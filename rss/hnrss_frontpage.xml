<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>黑客新闻：头版</title>
    <link>https://news.ycombinator.com/</link>
    <description>黑客新闻 RSS</description>
    <lastBuildDate>Wed, 24 Jul 2024 12:28:55 GMT</lastBuildDate>
    <item>
      <title>银行认为反洗钱“无效”，建议访问社交媒体</title>
      <link>https://www.therage.co/banks-aml-inefficient-access-to-social-media/</link>
      <description><![CDATA[文章网址：https://www.therage.co/banks-aml-inefficient-access-to-social-media/
评论网址：https://news.ycombinator.com/item?id=41056006
积分：12
评论数：4]]></description>
      <guid>https://www.therage.co/banks-aml-inefficient-access-to-social-media/</guid>
      <pubDate>Wed, 24 Jul 2024 11:53:27 GMT</pubDate>
    </item>
    <item>
      <title>遗产</title>
      <link>https://longform.asmartbear.com/legacy/</link>
      <description><![CDATA[文章网址：https://longform.asmartbear.com/legacy/
评论网址：https://news.ycombinator.com/item?id=41055934
积分：3
评论数：0]]></description>
      <guid>https://longform.asmartbear.com/legacy/</guid>
      <pubDate>Wed, 24 Jul 2024 11:44:30 GMT</pubDate>
    </item>
    <item>
      <title>Hyprland 现已独立，放弃 wlroots</title>
      <link>https://hyprland.org/news/independentHyprland/</link>
      <description><![CDATA[文章网址：https://hyprland.org/news/independentHyprland/
评论网址：https://news.ycombinator.com/item?id=41055507
积分：34
评论数：11]]></description>
      <guid>https://hyprland.org/news/independentHyprland/</guid>
      <pubDate>Wed, 24 Jul 2024 10:28:39 GMT</pubDate>
    </item>
    <item>
      <title>微鼠</title>
      <link>https://en.wikipedia.org/wiki/Micromouse</link>
      <description><![CDATA[文章网址：https://en.wikipedia.org/wiki/Micromouse
评论网址：https://news.ycombinator.com/item?id=41055230
积分：106
评论数：27]]></description>
      <guid>https://en.wikipedia.org/wiki/Micromouse</guid>
      <pubDate>Wed, 24 Jul 2024 09:36:44 GMT</pubDate>
    </item>
    <item>
      <title>我们打造了终极电动自行车电池，你可以修复和充电</title>
      <link>https://get.gouach.com/2</link>
      <description><![CDATA[文章网址：https://get.gouach.com/2
评论网址：https://news.ycombinator.com/item?id=41054824
积分：44
评论数：35]]></description>
      <guid>https://get.gouach.com/2</guid>
      <pubDate>Wed, 24 Jul 2024 08:30:03 GMT</pubDate>
    </item>
    <item>
      <title>固定地点</title>
      <link>https://without.boats/blog/pinned-places/</link>
      <description><![CDATA[文章网址：https://without.boats/blog/pinned-places/
评论网址：https://news.ycombinator.com/item?id=41054059
积分：27
评论数：3]]></description>
      <guid>https://without.boats/blog/pinned-places/</guid>
      <pubDate>Wed, 24 Jul 2024 06:11:09 GMT</pubDate>
    </item>
    <item>
      <title>Solaris 中的“门”：使用文件描述符的轻量级 RPC（1996 年）</title>
      <link>http://www.kohala.com/start/papers.others/doors.html</link>
      <description><![CDATA[文章网址：http://www.kohala.com/start/papers.others/doors.html
评论网址：https://news.ycombinator.com/item?id=41053761
积分：58
评论数：40]]></description>
      <guid>http://www.kohala.com/start/papers.others/doors.html</guid>
      <pubDate>Wed, 24 Jul 2024 05:02:30 GMT</pubDate>
    </item>
    <item>
      <title>用 C 语言编写的 Llama 3.1</title>
      <link>https://github.com/trholding/llama2.c/blob/master/runq.c</link>
      <description><![CDATA[文章网址：https://github.com/trholding/llama2.c/blob/master/runq.c
评论网址：https://news.ycombinator.com/item?id=41053201
积分：132
评论数：17]]></description>
      <guid>https://github.com/trholding/llama2.c/blob/master/runq.c</guid>
      <pubDate>Wed, 24 Jul 2024 02:49:44 GMT</pubDate>
    </item>
    <item>
      <title>展示 HN：我们制作了 glhf.chat – 运行几乎所有开源 LLM，包括 405B</title>
      <link>https://glhf.chat/landing/home</link>
      <description><![CDATA[试试吧！https://glhf.chat/嗨，HN！过去几个月，我们一直在开发一个网站，让您可以轻松在自动扩展的 GPU 集群上运行（几乎）任何开源 LLM。目前，我们正在研究如何定价，它是免费的，但我们预计它会比大多数 GPU 产品更便宜，因为我们可以运行多租户模型。与 Together AI、Fireworks 等不同，我们将运行开源 vLLM 项目支持的任何模型：我们没有硬编码列表。如果您想要特定模型或微调，则无需向我们索取：只需粘贴 Hugging Face 链接即可（只要 vLLM 支持基本模型架构，我们就会运行高达 ~640GB VRAM 的任何内容，或多或少会有一些开销缓冲区）。大型模型需要几分钟才能启动，但如果一群人试图使用相同的模型，它可能已经加载，根本不需要启动时间。Llama-3-70b 微调特别好，因为它们基本上是 8b 微调的增强版，很多人喜欢在本地运行，但没有 VRAM。我们预计 Llama-3.1 的微调在开始发布后也会非常出色。目前有一些注意事项 - 例如，虽然我们支持 Deepseek V2 架构，但由于一些底层 NVLink 限制（尽管我们正在努力），我们实际上只能运行其较小的“精简版”模型。但在大多数情况下，如果 vLLM 支持它，我们也应该支持它！我们认为 Llama-3.1-405B 发布日也是我们自己发布的好日子 - 如果您希望我们支持任何内容，或者您​​遇到任何问题，请在评论中告诉我们。我知道这不是“本地” Llama，但是，嗯，那是很多 GPU……

评论 URL：https://news.ycombinator.com/item?id=41052934
积分：144
评论数：79]]></description>
      <guid>https://glhf.chat/landing/home</guid>
      <pubDate>Wed, 24 Jul 2024 01:52:09 GMT</pubDate>
    </item>
    <item>
      <title>1976 年 Emacs 的起源</title>
      <link>https://onlisp.co.uk/On-the-Origin-of-Emacs-in-1976.html</link>
      <description><![CDATA[文章网址：https://onlisp.co.uk/On-the-Origin-of-Emacs-in-1976.html
评论网址：https://news.ycombinator.com/item?id=41052593
积分：119
评论数：41]]></description>
      <guid>https://onlisp.co.uk/On-the-Origin-of-Emacs-in-1976.html</guid>
      <pubDate>Wed, 24 Jul 2024 00:49:26 GMT</pubDate>
    </item>
    </channel>
</rss>